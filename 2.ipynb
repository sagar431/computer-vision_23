{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26596861",
   "metadata": {},
   "source": [
    "1. Explain convolutional neural network, and how does it work?\n",
    "2. How does refactoring parts of your neural network definition favor you?\n",
    "3. What does it mean to flatten? Is it necessary to include it in the MNIST CNN? What is the reason\n",
    "for this?\n",
    "\n",
    "4. What exactly does NCHW stand for?\n",
    "\n",
    "5. Why are there 7*7*(1168-16) multiplications in the MNIST CNN&#39;s third layer?\n",
    "\n",
    "6.Explain definition of receptive field?\n",
    "\n",
    "7. What is the scale of an activation&#39;s receptive field after two stride-2 convolutions? What is the\n",
    "reason for this?\n",
    "\n",
    "8. What is the tensor representation of a color image?\n",
    "\n",
    "9. How does a color input interact with a convolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e45272",
   "metadata": {},
   "source": [
    "## Answeer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9e9ce",
   "metadata": {},
   "source": [
    "1. A Convolutional Neural Network (CNN) is a type of neural network used for image classification and recognition. CNNs use a series of convolutional layers to extract features from the input image, and then use fully connected layers to classify the image. Each convolutional layer performs a series of convolution operations on the input image, using a set of learnable filters or kernels that are slid across the image to produce a set of feature maps. These feature maps are then passed through activation functions to produce non-linear transformations of the input. Pooling layers are then used to reduce the dimensionality of the feature maps while retaining the most important information, and the resulting feature maps are then fed into fully connected layers for classification.\n",
    "\n",
    "2. Refactoring parts of your neural network definition can help to improve its performance and efficiency. By breaking down the network into smaller, modular components, you can more easily experiment with different architectures and hyperparameters, and more quickly identify and fix errors or issues.\n",
    "\n",
    "3. Flattening refers to the process of converting a multidimensional tensor or array into a one-dimensional vector. In the MNIST CNN, flattening is necessary to convert the output of the convolutional and pooling layers into a format that can be fed into the fully connected layers. The reason for this is that fully connected layers require a one-dimensional input, whereas the convolutional and pooling layers produce multidimensional output.\n",
    "\n",
    "4. NCHW stands for \"batch size\", \"number of channels\", \"height\", and \"width\", respectively. It is a commonly used data format for representing images in convolutional neural networks, where the input image is represented as a tensor with dimensions (batch_size, num_channels, height, width).\n",
    "\n",
    "5. The MNIST CNN's third layer has 1168 filters, and the size of each filter is 7x7x16. Since the input to this layer is a 14x14x16 feature map, there are 7x7 positions at which each filter can be applied. Therefore, the total number of multiplications in this layer is 7x7x1168x16 = 858,752.\n",
    "\n",
    "6. The receptive field of a neuron in a convolutional neural network refers to the region of the input image that affects the output of that neuron. It is defined by the size of the filters used in the convolutional layers, as well as the stride and padding used to move the filters across the input image.\n",
    "\n",
    "7. After two stride-2 convolutions, the scale of an activation's receptive field is 4 times larger than before. This is because each stride-2 convolution reduces the spatial dimensions of the feature map by a factor of 2, while simultaneously increasing the receptive field of each neuron by a factor of 2.\n",
    "\n",
    "8. A color image is typically represented as a tensor with dimensions (height, width, num_channels), where the num_channels dimension represents the red, green, and blue color channels of each pixel. Alternatively, it can be represented as a tensor with dimensions (num_channels, height, width) in the NCHW format commonly used in deep learning.\n",
    "\n",
    "9. In a convolutional layer, a color input is processed by applying a set of filters to each color channel independently. Each filter produces a separate feature map for each channel, which are then summed to produce the final output feature map for that filter. This process is repeated for each filter in the layer, producing a set of output feature maps that capture different features of the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d730c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
